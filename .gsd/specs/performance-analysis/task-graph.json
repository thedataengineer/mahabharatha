{
  "feature": "performance-analysis",
  "version": "2.0",
  "generated": "2026-01-30T22:00:00Z",
  "total_tasks": 13,
  "estimated_duration_minutes": 120,
  "max_parallelization": 4,

  "tasks": [
    {
      "id": "PA-L1-001",
      "title": "Create performance types and package init",
      "description": "Create mahabharatha/performance/__init__.py with public exports (initially empty, populated after all modules exist) and mahabharatha/performance/types.py with all data models: Severity enum (CRITICAL/HIGH/MEDIUM/LOW/INFO with weights 25/10/5/2/0), PerformanceFactor dataclass (id, category, factor, description, cli_tools, security_note), PerformanceFinding dataclass (factor_id, factor_name, category, severity, message, file, line, tool, rule_id, suggestion), ToolStatus dataclass (name, available, version, factors_covered), CategoryScore dataclass (category, score Optional[float], findings, factors_checked, factors_total), DetectedStack dataclass (languages, frameworks, has_docker, has_kubernetes), PerformanceReport dataclass (overall_score, categories, tool_statuses, findings, factors_checked, factors_total, detected_stack, to_dict() method, top_issues(limit) method).",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": ["mahabharatha/performance/__init__.py", "mahabharatha/performance/types.py"],
        "modify": [],
        "read": ["mahabharatha/diagnostics/types.py"]
      },
      "acceptance_criteria": [
        "mahabharatha/performance/types.py defines Severity, PerformanceFactor, PerformanceFinding, ToolStatus, CategoryScore, DetectedStack, PerformanceReport",
        "All dataclasses have to_dict() or are simple enough for dataclasses.asdict()",
        "PerformanceReport.top_issues() returns sorted findings by severity",
        "ruff check passes on both files",
        "python -c 'from mahabharatha.performance.types import PerformanceReport' succeeds"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/types.py mahabharatha/performance/__init__.py && python -c 'from mahabharatha.performance.types import PerformanceReport, Severity, PerformanceFinding, DetectedStack; print(\"OK\")'",
        "timeout_seconds": 30
      },
      "estimate_minutes": 10
    },
    {
      "id": "PA-L1-002",
      "title": "Create factor catalog loader",
      "description": "1. Copy claudedocs/performance_evaluation_factors.json to mahabharatha/performance/data/factors.json as package data. 2. Create mahabharatha/performance/catalog.py with FactorCatalog class: load() classmethod reads factors.json via importlib.resources, returns list[PerformanceFactor]. filter_static_only() removes factors whose cli_tools contain only runtime tools (perf, perf stat, async-profiler, cachegrind, strace, ltrace, tcpdump, wrk, ab, k6, etc.). get_tool_factor_mapping() returns dict[str, list[int]] mapping tool_name to factor IDs. get_factors_by_category() returns dict[str, list[PerformanceFactor]]. STATIC_TOOLS constant listing the 11 supported tools.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": ["mahabharatha/performance/data/factors.json", "mahabharatha/performance/catalog.py"],
        "modify": [],
        "read": ["claudedocs/performance_evaluation_factors.json"]
      },
      "acceptance_criteria": [
        "mahabharatha/performance/data/factors.json is a valid copy of the factor catalog",
        "FactorCatalog.load() returns list of PerformanceFactor objects",
        "filter_static_only() removes runtime-only factors",
        "get_tool_factor_mapping() returns correct tool-to-factor-id mapping",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/catalog.py && python -c \"from mahabharatha.performance.catalog import FactorCatalog; c = FactorCatalog.load(); print(f'Loaded {len(c.factors)} factors, {len(c.filter_static_only())} static'); print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 10
    },
    {
      "id": "PA-L1-003",
      "title": "Create stack detector",
      "description": "Create mahabharatha/performance/stack_detector.py with detect_stack(project_path: str) -> DetectedStack function. Detection logic: 1. Languages: scan for *.py, *.js, *.ts, *.go, *.rs, *.java, *.rb, *.php file extensions. 2. Frameworks: check for package.json (node/react/vue/angular), requirements.txt/pyproject.toml/setup.py (python frameworks via content inspection), go.mod, Cargo.toml, pom.xml/build.gradle. 3. Infrastructure: Dockerfile/docker-compose.yml sets has_docker=True, any k8s manifest (deployment.yaml, service.yaml, etc.) or helmfile sets has_kubernetes=True. Return DetectedStack with languages: list[str], frameworks: list[str], has_docker: bool, has_kubernetes: bool.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": ["mahabharatha/performance/stack_detector.py"],
        "modify": [],
        "read": []
      },
      "acceptance_criteria": [
        "detect_stack() returns DetectedStack with languages, frameworks, has_docker, has_kubernetes",
        "Correctly detects Python projects",
        "Correctly detects Docker presence",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/stack_detector.py && python -c \"from mahabharatha.performance.stack_detector import detect_stack; s = detect_stack('.'); print(f'Languages: {s.languages}, Docker: {s.has_docker}'); print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 8
    },
    {
      "id": "PA-L1-004",
      "title": "Create tool registry",
      "description": "Create mahabharatha/performance/tool_registry.py with ToolRegistry class. TOOL_SPECS dict maps tool name to ToolSpec(check_cmd, version_flag, install_hint). All 11 tools: semgrep, radon, lizard, vulture, jscpd, deptry, pipdeptree, dive, hadolint, trivy, cloc. check_availability() method: uses shutil.which() for fast binary detection, runs version command for version string, returns list[ToolStatus]. Uses ThreadPoolExecutor(max_workers=8) for parallel checks. get_available() returns list of available tool names. print_advisory(console, missing) prints Rich panel showing missing tools and what factors they'd cover.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": ["mahabharatha/performance/tool_registry.py"],
        "modify": [],
        "read": []
      },
      "acceptance_criteria": [
        "ToolRegistry defines specs for all 11 tools",
        "check_availability() returns list[ToolStatus]",
        "Parallel checking via ThreadPoolExecutor",
        "print_advisory() produces Rich output for missing tools",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/tool_registry.py && python -c \"from mahabharatha.performance.tool_registry import ToolRegistry; r = ToolRegistry(); statuses = r.check_availability(); print(f'Checked {len(statuses)} tools'); print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 10
    },
    {
      "id": "PA-L2-001",
      "title": "Create base adapter and semgrep adapter",
      "description": "Create mahabharatha/performance/adapters/__init__.py with imports of all adapter classes. Create mahabharatha/performance/adapters/base.py with BaseToolAdapter ABC: name (str), tool_name (str), factors_covered (list[int]) properties. Abstract run(files, project_path, stack) -> list[PerformanceFinding]. is_applicable(stack) -> bool (default True). Create mahabharatha/performance/adapters/semgrep_adapter.py: SemgrepAdapter maps detected stack to semgrep registry configs (p/python, p/javascript, p/typescript, p/golang, p/dockerfile, p/performance). Runs semgrep --json --config=<configs> on project. Parses JSON output, maps rule IDs to factor IDs via RULE_FACTOR_MAP dict. Returns PerformanceFinding per match with severity mapped from semgrep severity.",
      "phase": "core",
      "level": 2,
      "dependencies": ["PA-L1-001", "PA-L1-002"],
      "files": {
        "create": ["mahabharatha/performance/adapters/__init__.py", "mahabharatha/performance/adapters/base.py", "mahabharatha/performance/adapters/semgrep_adapter.py"],
        "modify": [],
        "read": ["mahabharatha/performance/types.py", "mahabharatha/command_executor.py"]
      },
      "acceptance_criteria": [
        "BaseToolAdapter ABC defines run(), is_applicable(), name, tool_name, factors_covered",
        "SemgrepAdapter selects configs based on detected stack",
        "SemgrepAdapter parses semgrep JSON output into PerformanceFinding list",
        "ruff check passes on all three files"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/adapters/base.py mahabharatha/performance/adapters/semgrep_adapter.py mahabharatha/performance/adapters/__init__.py && python -c \"from mahabharatha.performance.adapters.base import BaseToolAdapter; from mahabharatha.performance.adapters.semgrep_adapter import SemgrepAdapter; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15
    },
    {
      "id": "PA-L2-002",
      "title": "Create radon, lizard, and vulture adapters",
      "description": "Create 3 adapters for Python/multi-lang code quality: 1. radon_adapter.py: RadonAdapter runs 'radon cc -j <files>' for cyclomatic complexity and 'radon mi -j <files>' for maintainability index. Parses JSON output. Maps to CPU/Compute and Code-Level Patterns factors. is_applicable only for Python stacks. 2. lizard_adapter.py: LizardAdapter runs 'lizard --xml <files>'. Parses XML output for function complexity, LOC, parameter count. Maps to CPU/Compute and Code Volume factors. Applicable to all languages. 3. vulture_adapter.py: VultureAdapter runs 'vulture <files> --min-confidence 80'. Parses text output (file:line: message). Maps to Code Volume (dead code) factors. Python only.",
      "phase": "core",
      "level": 2,
      "dependencies": ["PA-L1-001", "PA-L1-002"],
      "files": {
        "create": ["mahabharatha/performance/adapters/radon_adapter.py", "mahabharatha/performance/adapters/lizard_adapter.py", "mahabharatha/performance/adapters/vulture_adapter.py"],
        "modify": [],
        "read": ["mahabharatha/performance/adapters/base.py", "mahabharatha/performance/types.py"]
      },
      "acceptance_criteria": [
        "RadonAdapter parses radon cc/mi JSON output",
        "LizardAdapter parses lizard XML output",
        "VultureAdapter parses vulture text output",
        "Each maps findings to correct factor IDs",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/adapters/radon_adapter.py mahabharatha/performance/adapters/lizard_adapter.py mahabharatha/performance/adapters/vulture_adapter.py && python -c \"from mahabharatha.performance.adapters.radon_adapter import RadonAdapter; from mahabharatha.performance.adapters.lizard_adapter import LizardAdapter; from mahabharatha.performance.adapters.vulture_adapter import VultureAdapter; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15
    },
    {
      "id": "PA-L2-003",
      "title": "Create jscpd, deptry, pipdeptree, and cloc adapters",
      "description": "Create 4 adapters for code quality and volume: 1. jscpd_adapter.py: JscpdAdapter runs 'jscpd --reporters json <path>'. Parses JSON for duplicates (source, lines, tokens). Maps to Abstraction/Structure factors. 2. deptry_adapter.py: DeptryAdapter runs 'deptry <path> --json-output -'. Parses JSON for unused/missing deps. Maps to Dependencies factors. Python only. 3. pipdeptree_adapter.py: PipdeptreeAdapter runs 'pipdeptree --json'. Parses JSON dependency tree for depth, conflicts. Maps to Dependencies factors. Python only. 4. cloc_adapter.py: ClocAdapter runs 'cloc --json <path>'. Parses JSON for language breakdown, LOC, comment ratio. Maps to Code Volume factors.",
      "phase": "core",
      "level": 2,
      "dependencies": ["PA-L1-001", "PA-L1-002"],
      "files": {
        "create": ["mahabharatha/performance/adapters/jscpd_adapter.py", "mahabharatha/performance/adapters/deptry_adapter.py", "mahabharatha/performance/adapters/pipdeptree_adapter.py", "mahabharatha/performance/adapters/cloc_adapter.py"],
        "modify": [],
        "read": ["mahabharatha/performance/adapters/base.py", "mahabharatha/performance/types.py"]
      },
      "acceptance_criteria": [
        "JscpdAdapter parses jscpd JSON output for duplicates",
        "DeptryAdapter parses deptry JSON for dependency issues",
        "PipdeptreeAdapter parses pipdeptree JSON for dep tree analysis",
        "ClocAdapter parses cloc JSON for code volume metrics",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/adapters/jscpd_adapter.py mahabharatha/performance/adapters/deptry_adapter.py mahabharatha/performance/adapters/pipdeptree_adapter.py mahabharatha/performance/adapters/cloc_adapter.py && python -c \"from mahabharatha.performance.adapters.jscpd_adapter import JscpdAdapter; from mahabharatha.performance.adapters.cloc_adapter import ClocAdapter; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15
    },
    {
      "id": "PA-L2-004",
      "title": "Create dive, hadolint, and trivy adapters",
      "description": "Create 3 container/infra adapters: 1. dive_adapter.py: DiveAdapter runs 'dive <image> --json' or analyzes Dockerfile for layer efficiency. Maps to Container Image factors. is_applicable only when has_docker=True. 2. hadolint_adapter.py: HadolintAdapter runs 'hadolint --format json Dockerfile'. Parses JSON for Dockerfile best practices. Maps to Container Image factors. Docker only. 3. trivy_adapter.py: TrivyAdapter runs 'trivy fs --format json --scanners vuln,secret,misconfig <path>'. Parses JSON for CVEs, secrets, misconfigs. Maps to Security Patterns and Container Runtime factors.",
      "phase": "core",
      "level": 2,
      "dependencies": ["PA-L1-001", "PA-L1-002"],
      "files": {
        "create": ["mahabharatha/performance/adapters/dive_adapter.py", "mahabharatha/performance/adapters/hadolint_adapter.py", "mahabharatha/performance/adapters/trivy_adapter.py"],
        "modify": [],
        "read": ["mahabharatha/performance/adapters/base.py", "mahabharatha/performance/types.py"]
      },
      "acceptance_criteria": [
        "DiveAdapter analyzes Docker image layers",
        "HadolintAdapter parses hadolint JSON output",
        "TrivyAdapter parses trivy JSON for vulns/secrets/misconfig",
        "All three check is_applicable for Docker/K8s presence",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/adapters/dive_adapter.py mahabharatha/performance/adapters/hadolint_adapter.py mahabharatha/performance/adapters/trivy_adapter.py && python -c \"from mahabharatha.performance.adapters.dive_adapter import DiveAdapter; from mahabharatha.performance.adapters.trivy_adapter import TrivyAdapter; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 12
    },
    {
      "id": "PA-L3-001",
      "title": "Create performance aggregator",
      "description": "Create mahabharatha/performance/aggregator.py with PerformanceAuditor class. __init__(project_path) creates FactorCatalog, ToolRegistry, detects stack. run(files) method: 1. Check tool availability (parallel). 2. Filter catalog to static-only factors. 3. Select applicable adapters based on stack + available tools. 4. Run adapters in parallel via ThreadPoolExecutor. 5. Aggregate findings by category. 6. Compute per-category scores: score = max(0, 100 - (penalty / max(1, factors_checked)) * 10). Severity weights: CRITICAL=25, HIGH=10, MEDIUM=5, LOW=2, INFO=0. Categories with no tools get score=None. 7. Compute overall score as weighted average. 8. Return PerformanceReport.",
      "phase": "integration",
      "level": 3,
      "dependencies": ["PA-L2-001", "PA-L2-002", "PA-L2-003", "PA-L2-004"],
      "files": {
        "create": ["mahabharatha/performance/aggregator.py"],
        "modify": [],
        "read": ["mahabharatha/performance/types.py", "mahabharatha/performance/catalog.py", "mahabharatha/performance/stack_detector.py", "mahabharatha/performance/tool_registry.py", "mahabharatha/performance/adapters/base.py"]
      },
      "acceptance_criteria": [
        "PerformanceAuditor.run() returns PerformanceReport",
        "Adapters run in parallel via ThreadPoolExecutor",
        "Scoring math is correct per design spec",
        "Categories with no tools get score=None",
        "Graceful handling when zero tools available",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/aggregator.py && python -c \"from mahabharatha.performance.aggregator import PerformanceAuditor; a = PerformanceAuditor('.'); r = a.run([]); print(f'Score: {r.overall_score}, Checked: {r.factors_checked}/{r.factors_total}'); print('OK')\"",
        "timeout_seconds": 60
      },
      "estimate_minutes": 15
    },
    {
      "id": "PA-L3-002",
      "title": "Create performance formatters",
      "description": "Create mahabharatha/performance/formatters.py with 4 formatter functions: 1. format_rich(report, console): Rich tables grouped by category with color-coded scores (green >80, yellow >60, red <=60), expandable findings per category, tool availability summary panel, overall score gauge. 2. format_json(report) -> str: Full PerformanceReport.to_dict() as indented JSON. 3. format_sarif(report) -> str: SARIF 2.1.0 with driver name 'mahabharatha-performance', rules from factors, results from findings with locations. 4. format_markdown(report) -> str: H2 per category, findings table, summary section with overall score and tool coverage.",
      "phase": "integration",
      "level": 3,
      "dependencies": ["PA-L2-001", "PA-L2-002", "PA-L2-003", "PA-L2-004"],
      "files": {
        "create": ["mahabharatha/performance/formatters.py"],
        "modify": [],
        "read": ["mahabharatha/performance/types.py", "mahabharatha/commands/analyze.py"]
      },
      "acceptance_criteria": [
        "format_rich() produces Rich console output with category tables",
        "format_json() produces valid JSON matching PerformanceReport schema",
        "format_sarif() produces valid SARIF 2.1.0 structure",
        "format_markdown() produces markdown with category headers and tables",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/performance/formatters.py && python -c \"from mahabharatha.performance.formatters import format_json, format_sarif, format_markdown; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 12
    },
    {
      "id": "PA-L4-001",
      "title": "Integrate performance into analyze CLI",
      "description": "Modify mahabharatha/commands/analyze.py: 1. Add PERFORMANCE = 'performance' to CheckType enum. 2. Add PerformanceChecker(BaseChecker) bridge class: check(files) imports PerformanceAuditor lazily, runs audit, converts PerformanceReport to AnalysisResult (passed = score >= 70, score = overall_score, issues = top_issues(20)). Store full report as self._last_report for formatter access. 3. Register 'performance': PerformanceChecker() in AnalyzeCommand.__init__ checkers dict. 4. Update --check choices to include 'performance'. 5. In AnalyzeCommand.run(), when 'all' in checks, use list(self.checkers.keys()) but EXCLUDE 'performance'. 6. Add --performance boolean flag to CLI function. If set, override check='performance'. 7. Add 'markdown' to --format choices. 8. In CLI output section, when check=='performance', use perf-specific formatters from mahabharatha.performance.formatters instead of generic table. 9. Update __init__.py exports in mahabharatha/performance/ to include all public classes.",
      "phase": "integration",
      "level": 4,
      "dependencies": ["PA-L3-001", "PA-L3-002"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/commands/analyze.py", "mahabharatha/performance/__init__.py"],
        "read": ["mahabharatha/performance/aggregator.py", "mahabharatha/performance/formatters.py", "mahabharatha/performance/types.py"]
      },
      "acceptance_criteria": [
        "CheckType.PERFORMANCE exists",
        "PerformanceChecker bridge class works",
        "--performance flag triggers performance audit",
        "--check performance works",
        "--check all does NOT include performance",
        "--format markdown works",
        "Performance-specific formatters used for Rich/JSON/SARIF/Markdown output",
        "mahabharatha/performance/__init__.py exports all public classes",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check mahabharatha/commands/analyze.py mahabharatha/performance/__init__.py && python -c \"from mahabharatha.commands.analyze import CheckType, PerformanceChecker; assert hasattr(CheckType, 'PERFORMANCE'); print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 12
    },
    {
      "id": "PA-L5-001",
      "title": "Write unit tests for foundation modules",
      "description": "Create 4 test files: 1. tests/unit/test_performance_types.py: Test Severity ordering/weights, PerformanceFinding creation, PerformanceReport.to_dict() serialization, top_issues() sorting, CategoryScore with None score. 2. tests/unit/test_performance_catalog.py: Test FactorCatalog.load() returns all factors, filter_static_only() removes runtime-only, get_tool_factor_mapping() correctness, get_factors_by_category() grouping. 3. tests/unit/test_performance_stack.py: Test detect_stack() on tmp_path with Python files, with package.json, with Dockerfile, with k8s manifests, with empty dir. 4. tests/unit/test_performance_registry.py: Test ToolRegistry.check_availability() with mocked shutil.which (some available, some not), get_available() filtering, print_advisory() output.",
      "phase": "testing",
      "level": 5,
      "dependencies": ["PA-L4-001"],
      "files": {
        "create": ["tests/unit/test_performance_types.py", "tests/unit/test_performance_catalog.py", "tests/unit/test_performance_stack.py", "tests/unit/test_performance_registry.py"],
        "modify": [],
        "read": ["mahabharatha/performance/types.py", "mahabharatha/performance/catalog.py", "mahabharatha/performance/stack_detector.py", "mahabharatha/performance/tool_registry.py"]
      },
      "acceptance_criteria": [
        "All tests pass with pytest",
        "Tests use tmp_path for filesystem tests",
        "Tests mock shutil.which and subprocess for tool registry",
        "No external tools required to run tests",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check tests/unit/test_performance_types.py tests/unit/test_performance_catalog.py tests/unit/test_performance_stack.py tests/unit/test_performance_registry.py && python -m pytest tests/unit/test_performance_types.py tests/unit/test_performance_catalog.py tests/unit/test_performance_stack.py tests/unit/test_performance_registry.py -x -q 2>&1 | tail -5",
        "timeout_seconds": 60
      },
      "estimate_minutes": 15
    },
    {
      "id": "PA-L5-002",
      "title": "Write unit tests for adapters, aggregator, and formatters",
      "description": "Create 3 test files: 1. tests/unit/test_performance_adapters.py: Test each of the 11 adapters with mocked subprocess output. Store sample tool outputs as string constants. Test SemgrepAdapter config selection for different stacks. Test is_applicable() for language/infra-specific adapters. Test error handling when tool returns non-zero. 2. tests/unit/test_performance_aggregator.py: Test PerformanceAuditor with all tools mocked as unavailable (empty report, score=None). Test with synthetic findings (verify scoring math). Test parallel adapter execution. Test categories with mixed findings. 3. tests/unit/test_performance_formatters.py: Test format_json() produces valid JSON with expected keys. Test format_sarif() produces valid SARIF structure. Test format_markdown() produces expected headers and tables. Test format_rich() doesn't crash (capture console output).",
      "phase": "testing",
      "level": 5,
      "dependencies": ["PA-L4-001"],
      "files": {
        "create": ["tests/unit/test_performance_adapters.py", "tests/unit/test_performance_aggregator.py", "tests/unit/test_performance_formatters.py"],
        "modify": [],
        "read": ["mahabharatha/performance/adapters/", "mahabharatha/performance/aggregator.py", "mahabharatha/performance/formatters.py"]
      },
      "acceptance_criteria": [
        "All tests pass with pytest",
        "Tests mock all subprocess/tool calls",
        "Adapter tests cover all 11 adapters",
        "Aggregator tests verify scoring math",
        "Formatter tests validate output structure",
        "ruff check passes"
      ],
      "verification": {
        "command": "cd /Users/klambros/PycharmProjects/MAHABHARATHA && ruff check tests/unit/test_performance_adapters.py tests/unit/test_performance_aggregator.py tests/unit/test_performance_formatters.py && python -m pytest tests/unit/test_performance_adapters.py tests/unit/test_performance_aggregator.py tests/unit/test_performance_formatters.py -x -q 2>&1 | tail -5",
        "timeout_seconds": 60
      },
      "estimate_minutes": 15
    }
  ],

  "levels": {
    "1": {
      "name": "foundation",
      "tasks": ["PA-L1-001", "PA-L1-002", "PA-L1-003", "PA-L1-004"],
      "parallel": true,
      "estimated_minutes": 10,
      "depends_on_levels": []
    },
    "2": {
      "name": "adapters",
      "tasks": ["PA-L2-001", "PA-L2-002", "PA-L2-003", "PA-L2-004"],
      "parallel": true,
      "estimated_minutes": 15,
      "depends_on_levels": [1]
    },
    "3": {
      "name": "aggregation",
      "tasks": ["PA-L3-001", "PA-L3-002"],
      "parallel": true,
      "estimated_minutes": 15,
      "depends_on_levels": [2]
    },
    "4": {
      "name": "integration",
      "tasks": ["PA-L4-001"],
      "parallel": false,
      "estimated_minutes": 12,
      "depends_on_levels": [3]
    },
    "5": {
      "name": "testing",
      "tasks": ["PA-L5-001", "PA-L5-002"],
      "parallel": true,
      "estimated_minutes": 15,
      "depends_on_levels": [4]
    }
  },

  "conflict_matrix": {
    "description": "No file ownership conflicts - each file owned by exactly one task. Only analyze.py and __init__.py are modified (L4-001 only).",
    "conflicts": []
  }
}
