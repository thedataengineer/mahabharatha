{
  "feature": "design-task-manifest",
  "version": "2.0",
  "generated": "2026-01-30T12:00:00Z",
  "total_tasks": 6,
  "estimated_duration_minutes": 45,
  "max_parallelization": 2,
  "critical_path_minutes": 30,

  "tasks": [
    {
      "id": "DTM-L1-001",
      "title": "Add _build_design_manifest helper to design.py",
      "description": "Add a helper function `_build_design_manifest(feature: str, task_data: dict) -> dict` to `mahabharatha/commands/design.py`. It reads tasks from task_data['tasks'], builds a list of task entries with: subject `[L{level}] {title}`, description (task description + file ownership summary + verification command), active_form `Executing {title}`, and dependencies (list of task-graph IDs). Returns `{'feature': feature, 'generated': ISO timestamp, 'tasks': [...]}`. This function is a pure data transformer — no file I/O.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": [],
        "modify": ["mahabharatha/commands/design.py"],
        "read": []
      },
      "acceptance_criteria": [
        "_build_design_manifest function exists and is callable",
        "Returns dict with 'feature', 'generated', 'tasks' keys",
        "Each task entry has 'subject', 'description', 'active_form', 'dependencies'",
        "Subject format is [L{level}] {title}"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.commands.design import _build_design_manifest; m = _build_design_manifest('test', {'tasks': [{'id': 'T1', 'title': 'Test', 'level': 1, 'description': 'desc', 'dependencies': [], 'files': {'create': ['a.py'], 'modify': [], 'read': []}, 'verification': {'command': 'echo ok'}}]}); assert m['feature'] == 'test'; assert len(m['tasks']) == 1; assert m['tasks'][0]['subject'] == '[L1] Test'; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 10
    },
    {
      "id": "DTM-L1-002",
      "title": "Add load_design_manifest to task_sync.py",
      "description": "Add a function `load_design_manifest(spec_dir: Path) -> list[dict] | None` to `mahabharatha/task_sync.py`. It reads `design-tasks-manifest.json` from the given spec_dir if the file exists, parses JSON, and returns the 'tasks' list. Returns None if the file doesn't exist. Also update the `create_level_tasks()` docstring to remove the 'not yet integrated' caveat — reference the manifest as the handoff mechanism.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": [],
        "modify": ["mahabharatha/task_sync.py"],
        "read": []
      },
      "acceptance_criteria": [
        "load_design_manifest function exists and is importable",
        "Returns parsed task list when manifest file exists",
        "Returns None when manifest file is missing",
        "create_level_tasks docstring updated"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.task_sync import load_design_manifest; from pathlib import Path; result = load_design_manifest(Path('/nonexistent')); assert result is None; print('OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 8
    },
    {
      "id": "DTM-L2-001",
      "title": "Wire manifest writing into all design.py execution paths",
      "description": "In `mahabharatha/commands/design.py`, call `_build_design_manifest()` and write the result to `{spec_dir}/design-tasks-manifest.json` in all three execution paths: (1) full generation path (after create_task_graph_template, around line 137), (2) --validate-only path (after validate_task_graph, around line 99), (3) --update-backlog path (after generate_backlog_markdown, around line 113). Each path loads the task graph data and writes the manifest. Print a success message for each path.",
      "phase": "core",
      "level": 2,
      "dependencies": ["DTM-L1-001"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/commands/design.py"],
        "read": []
      },
      "acceptance_criteria": [
        "Full generation path writes design-tasks-manifest.json",
        "validate-only path writes design-tasks-manifest.json",
        "update-backlog path writes design-tasks-manifest.json",
        "Console prints success message for manifest in each path"
      ],
      "verification": {
        "command": "python -m ruff check mahabharatha/commands/design.py && python -m mypy mahabharatha/commands/design.py",
        "timeout_seconds": 60
      },
      "estimate_minutes": 10
    },
    {
      "id": "DTM-L2-002",
      "title": "Add manifest logging to level_coordinator.py",
      "description": "In `mahabharatha/level_coordinator.py`, in the `start_level()` method (around line 105), after creating ClaudeTask objects via `task_sync.create_level_tasks()`, add a call to `task_sync.load_design_manifest()` using the spec_dir derived from the feature name. Log at INFO level whether a design manifest was found and how many tasks it contains. This is informational only — does not change behavior.",
      "phase": "core",
      "level": 2,
      "dependencies": ["DTM-L1-002"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/level_coordinator.py"],
        "read": ["mahabharatha/task_sync.py"]
      },
      "acceptance_criteria": [
        "start_level logs manifest presence at INFO level",
        "Logs task count from manifest when present",
        "Logs 'no manifest found' when absent",
        "No behavior change — informational logging only"
      ],
      "verification": {
        "command": "python -m ruff check mahabharatha/level_coordinator.py && python -m mypy mahabharatha/level_coordinator.py",
        "timeout_seconds": 60
      },
      "estimate_minutes": 5
    },
    {
      "id": "DTM-L3-001",
      "title": "Write tests for design.py manifest creation",
      "description": "Add tests to `tests/unit/test_design_cmd.py` in a new `TestDesignManifest` class: (1) test_design_creates_manifest — full generation writes design-tasks-manifest.json, (2) test_manifest_structure — manifest has feature, generated, tasks[] with subject/description/active_form/dependencies fields, (3) test_validate_only_creates_manifest — --validate-only path also writes manifest, (4) test_update_backlog_creates_manifest — --update-backlog path also writes manifest. Use tmp_path fixtures and mock the Click runner. Follow existing test patterns in the file.",
      "phase": "testing",
      "level": 3,
      "dependencies": ["DTM-L2-001"],
      "files": {
        "create": [],
        "modify": ["tests/unit/test_design_cmd.py"],
        "read": ["mahabharatha/commands/design.py"]
      },
      "acceptance_criteria": [
        "TestDesignManifest class with 4 test methods",
        "All tests pass",
        "Tests verify manifest file creation and structure",
        "Tests cover all 3 execution paths"
      ],
      "verification": {
        "command": "python -m pytest tests/unit/test_design_cmd.py::TestDesignManifest -v",
        "timeout_seconds": 60
      },
      "estimate_minutes": 12
    },
    {
      "id": "DTM-L3-002",
      "title": "Write tests for task_sync manifest loading",
      "description": "Add tests to `tests/unit/test_task_sync.py` in a new `TestDesignManifestLoading` class: (1) test_load_design_manifest_exists — creates a manifest file, calls load_design_manifest, verifies returned task list, (2) test_load_design_manifest_missing — calls with nonexistent directory, returns None. Use tmp_path fixtures. Follow existing test patterns in the file.",
      "phase": "testing",
      "level": 3,
      "dependencies": ["DTM-L2-002"],
      "files": {
        "create": [],
        "modify": ["tests/unit/test_task_sync.py"],
        "read": ["mahabharatha/task_sync.py"]
      },
      "acceptance_criteria": [
        "TestDesignManifestLoading class with 2 test methods",
        "All tests pass",
        "Tests verify both present and missing manifest cases"
      ],
      "verification": {
        "command": "python -m pytest tests/unit/test_task_sync.py::TestDesignManifestLoading -v",
        "timeout_seconds": 60
      },
      "estimate_minutes": 8
    }
  ],

  "levels": {
    "1": {
      "name": "foundation",
      "tasks": ["DTM-L1-001", "DTM-L1-002"],
      "parallel": true,
      "estimated_minutes": 10,
      "depends_on_levels": []
    },
    "2": {
      "name": "core",
      "tasks": ["DTM-L2-001", "DTM-L2-002"],
      "parallel": true,
      "estimated_minutes": 10,
      "depends_on_levels": [1]
    },
    "3": {
      "name": "testing",
      "tasks": ["DTM-L3-001", "DTM-L3-002"],
      "parallel": true,
      "estimated_minutes": 12,
      "depends_on_levels": [2]
    }
  }
}
