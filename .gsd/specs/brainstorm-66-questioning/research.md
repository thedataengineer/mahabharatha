# Research: #66 Questioning Methodology

## Key Findings

### Single-question > Batch
- Socratic method fundamentally sequential: each answer informs next question
- Batch questions risk "interrogation" anti-pattern
- Single-question allows adaptive follow-up and deeper exploration
- Uncomfortable silence is OK — users need time to formulate answers

### AI Requirements Elicitation Trends
- Multi-agent LLM approaches gaining traction for requirements analysis
- PRE4AIM method: background → perspective-specific → prototype reaction (3 phases)
- Trained AI agents outperform humans on completeness, consistency, traceability
- Developers prefer diverse interaction modes: proactive, manual, hybrid

### Anti-Patterns to Avoid
- "Why" questions feel confrontational → use "what" framing
- Preface with "I'm curious..." to signal no judgment
- Don't Socratic-method everything — sometimes quick response is better

### Practical UX
- Start at stakeholder's comfort level
- Have structured question list but be willing to explore tangents
- Follow up on responses, encourage elaboration
- Replace open-ended with options where possible to reduce cognitive load

## Sources
- [Socratic Method for Software Requirements (Tigo)](https://en.tigosolutions.com/how-to-analyze-software-requirements-like-socrates-7-smart-questions-every-analyst-should-ask-65373)
- [Socratic Methods for Discovery (Medium)](https://medium.com/design-discovery-ux-life/applying-socratic-methods-for-better-discussion-and-discovery-4b8824b629c1)
- [AI Multiagent Requirements Elicitation (arXiv)](https://arxiv.org/html/2409.00038v1)
- [PRE4AIM Method (CEUR-WS)](https://ceur-ws.org/Vol-3959/PT-paper4.pdf)
- [AI Coding Assistants in Practice (ScienceDirect)](https://www.sciencedirect.com/science/article/abs/pii/S0950584924002155)
