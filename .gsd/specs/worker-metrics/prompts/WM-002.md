# WM-002: Create MetricsCollector class

## Overview
Create new `mahabharatha/metrics.py` module with MetricsCollector class and helper functions.

## Files to Create
- `mahabharatha/metrics.py`

## Requirements

### Helper Functions

```python
"""Metrics computation and aggregation for MAHABHARATHA."""

from datetime import datetime
from pathlib import Path
import json
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from mahabharatha.state import StateManager

from mahabharatha.types import (
    FeatureMetrics,
    LevelMetrics,
    TaskMetrics,
    WorkerMetrics,
)


def duration_ms(
    start: datetime | str | None,
    end: datetime | str | None,
) -> int | None:
    """Calculate duration in milliseconds between two timestamps.

    Args:
        start: Start timestamp (datetime or ISO string)
        end: End timestamp (datetime or ISO string)

    Returns:
        Duration in milliseconds, or None if either timestamp is None
    """
    if start is None or end is None:
        return None

    if isinstance(start, str):
        start = datetime.fromisoformat(start)
    if isinstance(end, str):
        end = datetime.fromisoformat(end)

    delta = end - start
    return int(delta.total_seconds() * 1000)


def calculate_percentile(values: list[int], percentile: int) -> int:
    """Calculate percentile from a list of values.

    Args:
        values: List of integer values
        percentile: Percentile to calculate (0-100)

    Returns:
        Percentile value, or 0 if list is empty
    """
    if not values:
        return 0

    sorted_values = sorted(values)
    n = len(sorted_values)
    index = int((percentile / 100) * (n - 1))
    return sorted_values[index]
```

### MetricsCollector Class

```python
class MetricsCollector:
    """Compute and aggregate metrics from state."""

    def __init__(self, state: "StateManager") -> None:
        """Initialize collector with state manager.

        Args:
            state: StateManager instance to read data from
        """
        self._state = state

    def compute_worker_metrics(self, worker_id: int) -> WorkerMetrics:
        """Compute metrics for a single worker.

        Args:
            worker_id: Worker ID to compute metrics for

        Returns:
            WorkerMetrics with computed values
        """
        worker_state = self._state.get_worker_state(worker_id)
        if not worker_state:
            return WorkerMetrics(worker_id=worker_id)

        # Calculate initialization time
        init_ms = None
        if worker_state.started_at and worker_state.ready_at:
            init_ms = duration_ms(worker_state.started_at, worker_state.ready_at)

        # Calculate uptime
        uptime_ms = 0
        if worker_state.started_at:
            uptime_ms = duration_ms(worker_state.started_at, datetime.now()) or 0

        # Get task stats from state
        # (would need to iterate tasks to get accurate counts)
        tasks_completed = worker_state.tasks_completed

        return WorkerMetrics(
            worker_id=worker_id,
            initialization_ms=init_ms,
            uptime_ms=uptime_ms,
            tasks_completed=tasks_completed,
            tasks_failed=0,  # Would need to count from tasks
            total_task_duration_ms=0,
            avg_task_duration_ms=0.0,
        )

    def compute_task_metrics(self, task_id: str) -> TaskMetrics:
        """Compute metrics for a single task.

        Args:
            task_id: Task ID to compute metrics for

        Returns:
            TaskMetrics with computed values
        """
        # Read task state
        task_state = self._state._state.get("tasks", {}).get(task_id, {})

        # Get timestamps
        created_at = task_state.get("created_at")
        claimed_at = task_state.get("claimed_at")
        started_at = task_state.get("started_at")
        completed_at = task_state.get("completed_at")

        # Calculate durations
        queue_wait = duration_ms(created_at, claimed_at) if created_at and claimed_at else None
        exec_duration = duration_ms(started_at, completed_at)
        total_duration = duration_ms(created_at, completed_at) if created_at else None

        # Get verification duration if available
        verification_ms = task_state.get("duration_ms")

        return TaskMetrics(
            task_id=task_id,
            queue_wait_ms=queue_wait,
            execution_duration_ms=exec_duration,
            verification_duration_ms=verification_ms,
            total_duration_ms=total_duration,
        )

    def compute_level_metrics(self, level: int) -> LevelMetrics:
        """Compute metrics for a level.

        Args:
            level: Level number to compute metrics for

        Returns:
            LevelMetrics with computed values
        """
        level_state = self._state.get_level_status(level) or {}

        # Get timestamps
        started_at = level_state.get("started_at")
        completed_at = level_state.get("completed_at")
        level_duration = duration_ms(started_at, completed_at)

        # Count tasks in this level
        tasks = self._state._state.get("tasks", {})
        level_tasks = [
            tid for tid, t in tasks.items()
            if t.get("level") == level
        ]

        # Get task durations for percentiles
        task_durations = []
        completed_count = 0
        failed_count = 0

        for tid in level_tasks:
            task = tasks.get(tid, {})
            if task.get("status") == "complete":
                completed_count += 1
                if duration := task.get("duration_ms"):
                    task_durations.append(duration)
            elif task.get("status") == "failed":
                failed_count += 1

        # Calculate stats
        avg_duration = sum(task_durations) / len(task_durations) if task_durations else 0.0
        p50 = calculate_percentile(task_durations, 50)
        p95 = calculate_percentile(task_durations, 95)

        return LevelMetrics(
            level=level,
            duration_ms=level_duration,
            task_count=len(level_tasks),
            completed_count=completed_count,
            failed_count=failed_count,
            avg_task_duration_ms=avg_duration,
            p50_duration_ms=p50,
            p95_duration_ms=p95,
        )

    def compute_feature_metrics(self) -> FeatureMetrics:
        """Compute all metrics for the feature.

        Returns:
            FeatureMetrics with all aggregated data
        """
        now = datetime.now()

        # Get started_at from state
        started_at = self._state._state.get("started_at")
        total_duration = duration_ms(started_at, now) if started_at else None

        # Get all workers
        workers = self._state.get_all_workers()
        worker_metrics = [
            self.compute_worker_metrics(wid) for wid in workers.keys()
        ]

        # Get all levels
        levels = self._state._state.get("levels", {})
        level_metrics = [
            self.compute_level_metrics(int(lvl)) for lvl in levels.keys()
        ]

        # Count tasks
        tasks = self._state._state.get("tasks", {})
        tasks_total = len(tasks)
        tasks_completed = len([t for t in tasks.values() if t.get("status") == "complete"])
        tasks_failed = len([t for t in tasks.values() if t.get("status") == "failed"])

        # Count completed levels
        levels_completed = len([
            l for l in levels.values() if l.get("status") == "complete"
        ])

        return FeatureMetrics(
            computed_at=now,
            total_duration_ms=total_duration,
            workers_used=len(workers),
            tasks_total=tasks_total,
            tasks_completed=tasks_completed,
            tasks_failed=tasks_failed,
            levels_completed=levels_completed,
            worker_metrics=worker_metrics,
            level_metrics=level_metrics,
        )

    def export_json(self, path: Path) -> None:
        """Export metrics to JSON file.

        Args:
            path: Path to write JSON file
        """
        metrics = self.compute_feature_metrics()
        path.write_text(json.dumps(metrics.to_dict(), indent=2))
```

## Verification

```bash
python -c "from mahabharatha.metrics import MetricsCollector, duration_ms, calculate_percentile; print('MetricsCollector OK')"
```

## Acceptance Criteria
- [ ] mahabharatha/metrics.py module exists
- [ ] duration_ms function handles datetime and string inputs
- [ ] duration_ms returns None when either input is None
- [ ] calculate_percentile returns 0 for empty list
- [ ] MetricsCollector.__init__ accepts StateManager
- [ ] compute_worker_metrics returns WorkerMetrics
- [ ] compute_task_metrics returns TaskMetrics
- [ ] compute_level_metrics returns LevelMetrics
- [ ] compute_feature_metrics returns FeatureMetrics
- [ ] export_json writes valid JSON file
