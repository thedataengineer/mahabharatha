{
  "feature": "worker-metrics",
  "version": "2.0",
  "generated": "2026-01-27T12:30:00Z",
  "total_tasks": 8,
  "estimated_duration_minutes": 45,
  "max_parallelization": 3,
  "critical_path_minutes": 25,

  "tasks": [
    {
      "id": "WM-001",
      "title": "Add metric dataclass types",
      "description": "Add WorkerMetrics, TaskMetrics, LevelMetrics, and FeatureMetrics dataclasses to types.py. Extend WorkerState with ready_at and last_task_completed_at fields. Extend TaskExecution TypedDict with claimed_at and duration_ms fields. Include to_dict and from_dict methods for all new types.",
      "phase": "foundation",
      "level": 1,
      "dependencies": [],
      "files": {
        "create": [],
        "modify": ["mahabharatha/types.py"],
        "read": []
      },
      "acceptance_criteria": [
        "WorkerMetrics dataclass with worker_id, initialization_ms, uptime_ms, tasks_completed, tasks_failed, total_task_duration_ms, avg_task_duration_ms fields",
        "TaskMetrics dataclass with task_id, queue_wait_ms, execution_duration_ms, verification_duration_ms, total_duration_ms fields",
        "LevelMetrics dataclass with level, duration_ms, task_count, completed_count, failed_count, avg_task_duration_ms, p50_duration_ms, p95_duration_ms fields",
        "FeatureMetrics dataclass with computed_at, total_duration_ms, workers_used, tasks_total, tasks_completed, tasks_failed, levels_completed, worker_metrics list, level_metrics list",
        "WorkerState extended with ready_at: datetime | None and last_task_completed_at: datetime | None",
        "TaskExecution TypedDict extended with claimed_at: str and duration_ms: int",
        "All dataclasses have to_dict() and from_dict() methods"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.types import WorkerMetrics, TaskMetrics, LevelMetrics, FeatureMetrics; print('Types OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15,
      "critical_path": true
    },
    {
      "id": "WM-002",
      "title": "Create MetricsCollector class",
      "description": "Create new mahabharatha/metrics.py module with MetricsCollector class. Include duration_ms() helper function to calculate milliseconds between timestamps. Include calculate_percentile() function for p50/p95 calculations. MetricsCollector should have methods: compute_worker_metrics(worker_id), compute_task_metrics(task_id), compute_level_metrics(level), compute_feature_metrics(), and export_json(path).",
      "phase": "core",
      "level": 2,
      "dependencies": ["WM-001"],
      "files": {
        "create": ["mahabharatha/metrics.py"],
        "modify": [],
        "read": ["mahabharatha/types.py", "mahabharatha/state.py"]
      },
      "acceptance_criteria": [
        "mahabharatha/metrics.py module exists",
        "duration_ms(start, end) function returns int | None",
        "calculate_percentile(values, percentile) function returns int",
        "MetricsCollector class with __init__(self, state: StateManager)",
        "compute_worker_metrics(worker_id) returns WorkerMetrics",
        "compute_task_metrics(task_id) returns TaskMetrics",
        "compute_level_metrics(level) returns LevelMetrics",
        "compute_feature_metrics() returns FeatureMetrics",
        "export_json(path) writes metrics to JSON file"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.metrics import MetricsCollector, duration_ms, calculate_percentile; print('MetricsCollector OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 20,
      "critical_path": true
    },
    {
      "id": "WM-003",
      "title": "Extend StateManager with metrics methods",
      "description": "Add new methods to StateManager for metrics: record_task_claimed(task_id, worker_id) to set claimed_at timestamp, record_task_duration(task_id, duration_ms) to set duration, store_metrics(metrics: FeatureMetrics) to persist computed metrics, get_metrics() to retrieve stored metrics. Update set_worker_ready to also record initialization timing.",
      "phase": "core",
      "level": 2,
      "dependencies": ["WM-001"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/state.py"],
        "read": ["mahabharatha/types.py"]
      },
      "acceptance_criteria": [
        "record_task_claimed(task_id, worker_id) method sets claimed_at timestamp",
        "record_task_duration(task_id, duration_ms) method sets duration_ms field",
        "store_metrics(metrics: FeatureMetrics) method persists metrics to state",
        "get_metrics() method returns FeatureMetrics | None",
        "set_worker_ready records ready_at timestamp (already exists, verify behavior)",
        "State includes 'metrics' section after store_metrics called"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.state import StateManager; s = StateManager('test-metrics-check'); print('StateManager OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15,
      "critical_path": true
    },
    {
      "id": "WM-004",
      "title": "Update state schema with metrics definitions",
      "description": "Extend .mahabharatha/schemas/state.schema.json to include metrics fields. Add claimed_at and duration_ms to task definition. Add ready_at and last_task_completed_at to worker definition. Add metrics section definition with computed_at, total_duration_ms, workers_used, tasks_total, tasks_completed, tasks_failed, worker_metrics array, level_metrics array.",
      "phase": "core",
      "level": 2,
      "dependencies": ["WM-001"],
      "files": {
        "create": [],
        "modify": [".mahabharatha/schemas/state.schema.json"],
        "read": []
      },
      "acceptance_criteria": [
        "task definition includes claimed_at and duration_ms properties",
        "worker definition includes ready_at and last_task_completed_at properties",
        "metrics definition added with all required fields",
        "Schema validates correctly with jsonschema"
      ],
      "verification": {
        "command": "python -c \"import json; d = json.load(open('.mahabharatha/schemas/state.schema.json')); assert 'metrics' in str(d); print('Schema OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 10,
      "critical_path": false
    },
    {
      "id": "WM-005",
      "title": "Integrate metrics into orchestrator",
      "description": "Update orchestrator.py to record timestamps at key lifecycle points: record started_at when worker spawns, record ready_at when worker becomes ready, record claimed_at when task is claimed, compute task duration_ms when task completes, trigger metrics computation on level complete. Import and use MetricsCollector.",
      "phase": "integration",
      "level": 3,
      "dependencies": ["WM-002", "WM-003"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/orchestrator.py"],
        "read": ["mahabharatha/metrics.py", "mahabharatha/state.py"]
      },
      "acceptance_criteria": [
        "Worker started_at recorded in _spawn_worker or equivalent",
        "Worker ready_at recorded when worker status becomes READY",
        "Task claimed_at recorded in claim_task flow",
        "Task duration_ms computed and stored on task completion",
        "MetricsCollector.compute_feature_metrics() called on level complete",
        "Metrics stored to state via store_metrics()"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.orchestrator import Orchestrator; print('Orchestrator import OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 20,
      "critical_path": true
    },
    {
      "id": "WM-006",
      "title": "Add metrics display to status command",
      "description": "Update status.py to display worker and level metrics. Add show_worker_metrics() function to format worker timing table. Add show_level_metrics() function to show level timing with p50/p95. Update show_status() to call metrics display functions. Update JSON output to include metrics section.",
      "phase": "integration",
      "level": 3,
      "dependencies": ["WM-002"],
      "files": {
        "create": [],
        "modify": ["mahabharatha/commands/status.py"],
        "read": ["mahabharatha/metrics.py"]
      },
      "acceptance_criteria": [
        "Worker metrics table shows init time, tasks completed, avg duration, uptime",
        "Level metrics show duration, task count, p50/p95",
        "JSON output includes metrics section",
        "Graceful handling when no metrics available",
        "Format durations as human-readable (1.2s, 4m30s)"
      ],
      "verification": {
        "command": "python -c \"from mahabharatha.commands.status import show_status; print('Status import OK')\"",
        "timeout_seconds": 30
      },
      "estimate_minutes": 15,
      "critical_path": false
    },
    {
      "id": "WM-007",
      "title": "Create unit tests for MetricsCollector",
      "description": "Create tests/unit/test_metrics.py with comprehensive unit tests for MetricsCollector and helper functions. Test duration_ms with valid timestamps, None values, string vs datetime. Test calculate_percentile with various list sizes including empty. Test all compute_* methods with mocked state data.",
      "phase": "testing",
      "level": 4,
      "dependencies": ["WM-002"],
      "files": {
        "create": ["tests/unit/test_metrics.py"],
        "modify": [],
        "read": ["mahabharatha/metrics.py"]
      },
      "acceptance_criteria": [
        "test_duration_ms_valid_timestamps passes",
        "test_duration_ms_with_none passes",
        "test_duration_ms_with_strings passes",
        "test_calculate_percentile_p50 passes",
        "test_calculate_percentile_p95 passes",
        "test_calculate_percentile_empty_list passes",
        "test_compute_worker_metrics passes",
        "test_compute_task_metrics passes",
        "test_compute_level_metrics passes",
        "test_compute_feature_metrics passes",
        "test_export_json passes",
        "All tests use appropriate mocking"
      ],
      "verification": {
        "command": "pytest tests/unit/test_metrics.py -v --tb=short",
        "timeout_seconds": 120
      },
      "estimate_minutes": 25,
      "critical_path": false
    },
    {
      "id": "WM-008",
      "title": "Create integration tests for metrics",
      "description": "Create tests/integration/test_metrics_integration.py with integration tests. Test that metrics persist to state file correctly. Test that status command displays metrics. Test end-to-end metrics flow with mock orchestrator run.",
      "phase": "testing",
      "level": 4,
      "dependencies": ["WM-005", "WM-006"],
      "files": {
        "create": ["tests/integration/test_metrics_integration.py"],
        "modify": [],
        "read": ["mahabharatha/orchestrator.py", "mahabharatha/commands/status.py"]
      },
      "acceptance_criteria": [
        "test_metrics_persist_to_state passes",
        "test_metrics_computed_on_level_complete passes",
        "test_status_displays_metrics passes",
        "test_json_status_includes_metrics passes",
        "Tests use temporary state files",
        "Tests clean up after themselves"
      ],
      "verification": {
        "command": "pytest tests/integration/test_metrics_integration.py -v --tb=short",
        "timeout_seconds": 120
      },
      "estimate_minutes": 20,
      "critical_path": false
    }
  ],

  "levels": {
    "1": {
      "name": "foundation",
      "tasks": ["WM-001"],
      "parallel": false,
      "estimated_minutes": 15,
      "depends_on_levels": []
    },
    "2": {
      "name": "core",
      "tasks": ["WM-002", "WM-003", "WM-004"],
      "parallel": true,
      "estimated_minutes": 20,
      "depends_on_levels": [1]
    },
    "3": {
      "name": "integration",
      "tasks": ["WM-005", "WM-006"],
      "parallel": true,
      "estimated_minutes": 20,
      "depends_on_levels": [2]
    },
    "4": {
      "name": "testing",
      "tasks": ["WM-007", "WM-008"],
      "parallel": true,
      "estimated_minutes": 25,
      "depends_on_levels": [3]
    }
  },

  "conflict_matrix": {
    "description": "No file conflicts - each file owned by single task",
    "conflicts": []
  }
}
